<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"vikingstudyhard.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="第四章 LinearRegression with multiple variables">
<meta property="og:type" content="article">
<meta property="og:title" content="【Andrew Ng】Machine Learning | 4 LinearRegression with multiple variables">
<meta property="og:url" content="https://vikingstudyhard.github.io/2019/01/20/MachineLearning_AndrewNg_4/index.html">
<meta property="og:site_name" content="加载起来特别特别慢的小博客">
<meta property="og:description" content="第四章 LinearRegression with multiple variables">
<meta property="og:locale">
<meta property="og:image" content="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/3ED9C7B973E1F2C6541549548F5F4205.jpg">
<meta property="og:image" content="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/46E129573AB8B4C4BB4A7EE65CA8C0F1.jpg">
<meta property="og:image" content="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/EBB8049827DD074604F14C3C11778088.jpg">
<meta property="og:image" content="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/4E5612347FE5DAF3749E19D6699AC4BC.jpg">
<meta property="og:image" content="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/CEE886A17ECBE20DC6D1CE233E9354B2.jpg">
<meta property="og:image" content="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/C6927DD0D2F8BE99E48605A63EF3AD08.jpg">
<meta property="og:image" content="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/1E8B7DE2D8B45117DA486E8E515A456F.jpg">
<meta property="og:image" content="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/47A67903FC373617014D2E7E42F3A32D.jpg">
<meta property="og:image" content="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/E3C1A1C5B4575F68DE05B84A1B8C57F3.jpg">
<meta property="og:image" content="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/1BB4DFE1C7EB5F75BD84B8E11C29404C.jpg">
<meta property="og:image" content="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/2A6D6478D852BE0ECED285D90893991E.jpg">
<meta property="article:published_time" content="2019-01-19T16:00:00.000Z">
<meta property="article:modified_time" content="2021-05-11T06:56:58.521Z">
<meta property="article:author" content="VikingWang">
<meta property="article:tag" content="Andrew Ng">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/3ED9C7B973E1F2C6541549548F5F4205.jpg">

<link rel="canonical" href="https://vikingstudyhard.github.io/2019/01/20/MachineLearning_AndrewNg_4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>【Andrew Ng】Machine Learning | 4 LinearRegression with multiple variables | 加载起来特别特别慢的小博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">加载起来特别特别慢的小博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">图片墙第一弹第二弹欢迎惠顾！</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-photo">

    <a href="/photo/" rel="section"><i class="fa fa-camera fa-fw"></i>photo</a>

  </li>
        <li class="menu-item menu-item-photo2">

    <a href="/photo2/" rel="section"><i class="fa fa-camera fa-fw"></i>photo2</a>

  </li>
        <li class="menu-item menu-item-friends">

    <a href="/friends/" rel="section"><i class="fa fa-rocket fa-fw"></i>friends</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://vikingstudyhard.github.io/2019/01/20/MachineLearning_AndrewNg_4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.JPG">
      <meta itemprop="name" content="VikingWang">
      <meta itemprop="description" content="这是一个需要耐心等着加载的博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="加载起来特别特别慢的小博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          【Andrew Ng】Machine Learning | 4 LinearRegression with multiple variables
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-01-20 00:00:00" itemprop="dateCreated datePublished" datetime="2019-01-20T00:00:00+08:00">2019-01-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-05-11 14:56:58" itemprop="dateModified" datetime="2021-05-11T14:56:58+08:00">2021-05-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-learning/" itemprop="url" rel="index"><span itemprop="name">Machine learning</span></a>
                </span>
            </span>

          
            <div class="post-description">第四章 LinearRegression with multiple variables</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>第四章 LinearRegression with multiple variables </p>
<h1 id="1-Multiple-Features-多特征量"><a href="#1-Multiple-Features-多特征量" class="headerlink" title="1 Multiple Features 多特征量"></a>1 Multiple Features 多特征量</h1><div align=center>
  <img width=700 src="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/3ED9C7B973E1F2C6541549548F5F4205.jpg" >
</div>

<p>$m$ = the number of training examples 样本数量<br>$n$ = the number of features 上图中 $n=4$<br>$x^{(i)}$ = the input (features) of the $i^{th}$ training example<br>上图中 $x^{(2)}=\begin{bmatrix}<br>1416 \<br>3 \<br>2 \<br>40<br>\end{bmatrix}$<br>$x^{(i)}_j$ = value of feature $j$ in the $i^{th}$ training example 第$i$个样本的第$j$个特征<br>上图中 $x^{(2)}_3 = 2$ </p>
<p>假设函数变成：$h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_3+\theta_4x_4+…+\theta_nx_n$</p>
<p>定义$x_0=1$，则$x^{(i)}_0 = 1$，那么特征向量$x=\begin{bmatrix}<br>x_0 \<br>x_1 \<br>x_2 \<br>\vdots  \<br>x_n<br>\end{bmatrix}\in \mathbb{R}^{n+1}$，参数向量$\theta=\begin{bmatrix}<br>\theta_0 \<br>\theta_1 \<br>\theta_2 \<br>\vdots \<br>\theta_n<br>\end{bmatrix}\in \mathbb{R}^{n+1}$</p>
<p>假设函数可写为:</p>
<p>$$\begin{align*} h_\theta(x) &amp;=\theta_0x_0+\theta_1x_1+\theta_2x_2+\theta_3x_3+\theta_4x_4+…+\theta_nx_n\<br> &amp;= \theta^Tx \<br> &amp;= \begin{bmatrix} \theta_0 &amp;\theta_1 &amp; \theta_2 &amp; …  &amp; \theta_n<br> \end{bmatrix} \begin{bmatrix}<br>x_0 \<br>x_1 \<br>x_2 \<br>\vdots  \<br>x_n<br> \end{bmatrix}<br>\end{align*}$$</p>
<p>Multivariate linear regression 多元线性回归</p>
<h1 id="2-Gradient-descent-for-multiple-variables"><a href="#2-Gradient-descent-for-multiple-variables" class="headerlink" title="2 Gradient descent for multiple variables"></a>2 Gradient descent for multiple variables</h1><p>多元梯度下降<br>Hypothesis: $h_\theta(x)=\theta^Tx=\theta_0x_0+\theta_1x_1+\theta_2x_2+\theta_3x_3+\theta_4x_4+…+\theta_nx_n$</p>
<p>Parameters: $\theta=\begin{bmatrix}<br>\theta_0 \<br>\theta_1 \<br>\theta_2 \<br>\vdots  \<br>\theta_n<br>\end{bmatrix}$</p>
<p>Cost function: $J(\theta)=\frac{1}{2m}\sum_{i=1}^{m}\left ( h_\theta (x^{(i)}) - y^{(i)} \right )^2$</p>
<p>Gradient descent:<br>Repeat{<br>    $\quad \theta _j := \theta _j - \alpha \frac{\partial }{\partial \theta  _j}J(\theta)$<br>}<br>对于 $j=0,…,n$ 同时更新</p>
<h2 id="只有一个特征值"><a href="#只有一个特征值" class="headerlink" title="只有一个特征值"></a>只有一个特征值</h2><p>$n=1$时<br>Repeat{<br>$\quad \theta <em>0 := \theta <em>0 - \alpha \underbrace{\frac{1}{m}\sum</em>{i=1}^{m}\left ( h_\theta (x^{(i)}) - y^{(i)} \right )}</em>{\frac{\partial }{\partial \theta  _0}J(\theta)}$<br>$\quad \theta _1 := \theta <em>1 - \alpha \frac{1}{m}\sum</em>{i=1}^{m}\left ( h_\theta (x^{(i)}) - y^{(i)} \right )\cdot x^{(i)}$<br>(同时更新$\theta_0$ $\theta_1$)<br>}</p>
<h2 id="不止一个特征值"><a href="#不止一个特征值" class="headerlink" title="不止一个特征值"></a>不止一个特征值</h2><p>$n\geq1$时<br>Repeat{<br>$\quad \theta _j := \theta <em>j - \alpha \frac{1}{m}\sum</em>{i=1}^{m}\left ( h_\theta (x^{(i)}) - y^{(i)} \right )\cdot x^{(i)}_j$<br>(同时更新$\theta_j$ for $j=0,…,n$)<br>}</p>
<p>$\theta _0 := \theta <em>0 - \alpha \frac{1}{m}\sum</em>{i=1}^{m}\left ( h_\theta (x^{(i)}) - y^{(i)} \right )\cdot x^{(i)}_0$<br>$\theta _1 := \theta <em>1 - \alpha \frac{1}{m}\sum</em>{i=1}^{m}\left ( h_\theta (x^{(i)}) - y^{(i)} \right )\cdot x^{(i)}_1$<br>$\theta _2 := \theta <em>2 - \alpha \frac{1}{m}\sum</em>{i=1}^{m}\left ( h_\theta (x^{(i)}) - y^{(i)} \right )\cdot x^{(i)}_2$<br>…</p>
<h1 id="3-Gradient-Descent-in-Practice-I-Feature-Scaling-特征缩放"><a href="#3-Gradient-Descent-in-Practice-I-Feature-Scaling-特征缩放" class="headerlink" title="3 Gradient Descent in Practice I - Feature Scaling 特征缩放"></a>3 Gradient Descent in Practice I - Feature Scaling 特征缩放</h1><p>确保features在相似的范围内，使梯度下降更快地收敛</p>
<blockquote>
<p>E.g.<br>$x_1$ = size (0-2000 feet$^2$)<br>$x_2$ = number of bedrooms (1-5)</p>
</blockquote>
<div align=center>
  <img width=348 src="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/46E129573AB8B4C4BB4A7EE65CA8C0F1.jpg" >
</div>

<p>梯度下降反复来回振荡，需要花很长时间找到全局最小值。</p>
<blockquote>
<p>E.g.<br>$x_1 =\frac{ size (feet^2)}{2000}$</p>
<p>$x_2 =\frac{number\ of\ bedrooms}{5}$</p>
</blockquote>
<div align=center>
  <img width=262 src="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/EBB8049827DD074604F14C3C11778088.jpg" >
</div>

<p>使 $0\leq x_i\leq1$，收敛更快。</p>
<p>将每个feature的取值约束到 $-1\leq x_i\leq1$</p>
<p>Mean normalization 均值归一化<br>用 $x_i-\mu_i$ 代替 $x_i$，使特征值的平均值约为$0$，但是不应用于 $x_0$，因为$x_0$恒等$1$。</p>
<blockquote>
<p>E.g.<br>$x_1 =\frac{ size - 1000 }{2000}$</p>
<p>$x_2 =\frac{\#bedrooms-2}{5}$</p>
</blockquote>
<p>$-0.5\leq x_i\leq0.5$，收敛更快。</p>
<p>两者整合起来就是：<br>$$x_i:=\frac{x_i- \mu_i}{s_i}$$<br>其中，$\mu_i$ 是训练集中$x_i$的平均值，${s_i}$是该特征值的范围，即（max -<br>min），或者是标准差standard deviation。</p>
<h1 id="4-Gradient-Descent-in-Practice-II-Learning-rate-学习率"><a href="#4-Gradient-Descent-in-Practice-II-Learning-rate-学习率" class="headerlink" title="4 Gradient Descent in Practice II - Learning rate 学习率"></a>4 Gradient Descent in Practice II - Learning rate 学习率</h1><h2 id="如何确保梯度下降是正确工作的"><a href="#如何确保梯度下降是正确工作的" class="headerlink" title="如何确保梯度下降是正确工作的"></a>如何确保梯度下降是正确工作的</h2><h3 id="Debugging-gradient-descent"><a href="#Debugging-gradient-descent" class="headerlink" title="Debugging gradient descent"></a>Debugging gradient descent</h3><p>作图</p>
<div align=center>
  <img width=483 src="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/4E5612347FE5DAF3749E19D6699AC4BC.jpg" >
</div>

<p>横轴代表的是迭代次数，而不是$\theta$。<br>曲线上的点表示：用某个迭代次数后得到的$\theta$，计算$J(\theta)$的值。<br>正常情况下：<strong>每一步迭代后，$J(\theta)$都应该下降</strong>，例如图中300到400迭代次数中，曲线平坦，也就是说差不多已经收敛了。</p>
<h3 id="Automatic-convergence-test"><a href="#Automatic-convergence-test" class="headerlink" title="Automatic convergence test"></a>Automatic convergence test</h3><p>自动收敛测试，判断是否已经收敛。<br>如果代价函数$J(\theta)$一步迭代后的下降小于一个很小的值$\varepsilon$，就可以判断已经收敛。$\varepsilon$可以是$10_{-3}$，通常选择一个合适的阈值$\varepsilon$很困难。所以一般都用上面的方法。</p>
<h2 id="如何选择学习率-alpha"><a href="#如何选择学习率-alpha" class="headerlink" title="如何选择学习率 $\alpha$"></a>如何选择学习率 $\alpha$</h2><div align=center>
  <img width=530 src="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/CEE886A17ECBE20DC6D1CE233E9354B2.jpg" >
</div>

<p>如果$J(\theta)$的值反而增加了，或者一会增加一会减少，那就应该使用较小的$\alpha$。<br>但如果$\alpha$过小，收敛的过程会特别慢。</p>
<p>$\alpha$可以尝试为 …0.001,0.003,0.01, 0.03,0.1,0.3,1,…然后绘制$J(\theta)$随迭代次数变化的曲线。</p>
<h1 id="5-Features-and-Polynomial-Regression-特征与多项式回归"><a href="#5-Features-and-Polynomial-Regression-特征与多项式回归" class="headerlink" title="5 Features and Polynomial Regression 特征与多项式回归"></a>5 Features and Polynomial Regression 特征与多项式回归</h1><p>We can <strong>combine</strong> multiple features into one.<br>For example, we can combine $x_1$ and $x_2$ into a new feature $x_3$ by taking   $x_1\cdot  x_2 $.</p>
<h2 id="Housing-prices-prediction"><a href="#Housing-prices-prediction" class="headerlink" title="Housing prices prediction"></a>Housing prices prediction</h2><p>$h_\theta(x)=\theta_0+\theta_1\times frontage + \theta_2\times depth$<br>房子的临街宽度和垂直宽度</p>
<div align=center>
  <img width=595 src="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/C6927DD0D2F8BE99E48605A63EF3AD08.jpg" >
</div>


<p>可以直接将面积作为新的特征，得到更好的模型。</p>
<p>quadratic model 二次模型 过了对称轴会下降 不适合 –&gt; cubic model 三次模型</p>
<div align=center>
  <img width=663 src="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/1E8B7DE2D8B45117DA486E8E515A456F.jpg" >
</div>


<p>要找到合适的模型，并且进行特征缩放，使值的范围变得具有可比性。</p>
<p>或者$h_\theta(x)=\theta_0+\theta_1(size) + \theta_2 \sqrt{(size)}$<br>函数到后来不会下降，而是趋于平缓。</p>
<h1 id="6-Linear-regression-with-multiple-variables-–-Normal-equation-正规方程"><a href="#6-Linear-regression-with-multiple-variables-–-Normal-equation-正规方程" class="headerlink" title="6 Linear regression with multiple variables – Normal equation 正规方程"></a>6 Linear regression with multiple variables – Normal equation 正规方程</h1><p>正规方程：对于某些线性回归问题，有更好的方法求参数 $\theta$的最优值。</p>
<p>梯度下降法(gradient descent)中为了最小化代价函数 $J(\theta)$，使用迭代算法(iterative algorithm)，经过许多步迭代，收敛(converge)到全局最小值。</p>
<p>正规方程可以一次直接求解得到$\theta$的最优值，而不用多次迭代。</p>
<h2 id="Intuition"><a href="#Intuition" class="headerlink" title="Intuition"></a>Intuition</h2><p>当$\theta$是实数，导数为0时$\theta$的值即为$\theta$的最优值</p>
<div align=center>
  <img width=757 src="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/47A67903FC373617014D2E7E42F3A32D.jpg" >
</div>


<p>当$\theta$是n+1维的参数向量，需要逐个对参数$\theta_j$求$J(\theta)$的偏导数，并全部置0，求出所有$\theta$的值。</p>
<div align=center>
  <img width=771 src="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/E3C1A1C5B4575F68DE05B84A1B8C57F3.jpg" >
</div>


<p>这样做很复杂。</p>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><div align=center>
  <img width=762 src="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/1BB4DFE1C7EB5F75BD84B8E11C29404C.jpg" >
</div>

<p>为了实现正规方程法，需要加上$x_0$，取值永远是1。通过训练样本的所有特征变量建立 $m\times (n+1)$ 的矩阵  $X$，通过所有y值建立 $m$ 维向量 $y$。其中$m$是训练样本数量，$n$是特征变量的数量。</p>
<div align=center>
  <img width=800 src="https://vikingstudyhard.github.io/images/MachineLearning_AndrewNg_4/2A6D6478D852BE0ECED285D90893991E.jpg" >
</div>


<p>计算$$\theta=(X^TX)^{-1}X^Ty$$</p>
<blockquote>
<p>X transpose X  inverse times X transpose y</p>
</blockquote>
<p>可以得到使代价函数最小化的$\theta$</p>
<h2 id="design-matrix-设计矩阵"><a href="#design-matrix-设计矩阵" class="headerlink" title="design matrix 设计矩阵"></a>design matrix 设计矩阵</h2><p>有$m$个样本：$(x^{(1)},y^{(1)}),…,(x^{(m)},y^{(m)})$<br>有$n$个特征：$x{(i)}=\begin{bmatrix}<br>x^{(i)}_0 \<br>x^{(i)}_1 \<br>x^{(i)}_2 \<br>…\<br>x^{(i)}_n<br>\end{bmatrix} \in \mathbb{R}^{(n+1)}$</p>
<p>则 $X=\begin{bmatrix}<br>—(x^{(1)})^T— \<br>—(x^{(2)})^T— \<br>—(x^{(3)})^T— \<br>\vdots \<br>—(x^{(m)})^T—<br>\end{bmatrix}$</p>
<blockquote>
<p>E.g.<br>若$x{(i)}=\begin{bmatrix}<br>1 \<br>x^{(i)}_1<br>\end{bmatrix} $，则 $X=\begin{bmatrix}<br>1, x^{(1)}_1 \<br>1, x^{(2)}_1 \<br>1, x^{(3)}_1 \<br>\vdots \<br>1, x^{(m)}_1<br>\end{bmatrix}$ ，$y=\begin{bmatrix}<br>y^{(1)} \<br>y^{(2)} \<br>y^{(3)} \<br>\vdots \<br>y^{(m)}<br>\end{bmatrix}$<br>然后计算$\theta=(X^TX)^{-1}X^Ty$即可。</p>
</blockquote>
<p>Octave</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pinv(X&#x27;*X)*X&#x27;*y</span><br></pre></td></tr></table></figure>

<p>其中，X’为转置，pinv为求逆函数。</p>
<p>使用正规方程不需要特征缩放(feature scaling)。</p>
<h2 id="梯度下降和正规方程的优缺点"><a href="#梯度下降和正规方程的优缺点" class="headerlink" title="梯度下降和正规方程的优缺点"></a>梯度下降和正规方程的优缺点</h2><ul>
<li><p>Gradient Descent</p>
<ul>
<li>缺点<ul>
<li>需要选择学习速率 $\alpha$</li>
<li>需要多次迭代</li>
</ul>
</li>
<li>优点<ul>
<li>$n$ 很大（特征变量很多）时也会运行很好</li>
</ul>
</li>
</ul>
</li>
<li><p>Normal Equation</p>
<ul>
<li>优点<ul>
<li>不需要选择学习速率 $\alpha$</li>
<li>不需要迭代   </li>
</ul>
</li>
<li>缺点<ul>
<li>需要计算 $(X^TX)^{-1}$ ，$X^TX$是$n\times n$的矩阵，而求逆矩阵的代价以矩阵维度的三次方增长，即$O(n^3)$</li>
<li>$n$ 很大（特征变量很多）时会很慢</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>所以，$n$ 很大（$n=10^6$ 以上）时用梯度下降法；$n$ 很小时（n为几万以下），用正规方程。</p>
<h1 id="7-Linear-regression-with-multiple-variables-–-Normal-equation-and-non-invertibility"><a href="#7-Linear-regression-with-multiple-variables-–-Normal-equation-and-non-invertibility" class="headerlink" title="7 Linear regression with multiple variables – Normal equation and non-invertibility"></a>7 Linear regression with multiple variables – Normal equation and non-invertibility</h1><p>正规方程以及不可逆性</p>
<p>$X^TX$不可逆怎么办<br>不可逆矩阵 non-invertible matrices：奇异矩阵 singular matrices / 退化矩阵 degenerate matrices</p>
<h2 id="X-TX-不可逆的两种原因"><a href="#X-TX-不可逆的两种原因" class="headerlink" title="$X^TX$不可逆的两种原因"></a>$X^TX$不可逆的两种原因</h2><ul>
<li>冗余特征(线性相关)<br>e.g. $x_1=size \  in \  feet^2$, $x_2=size \  in  \  m^2$<br>  $1\ m = 3.28\ feet$，即$x_1 = 3.28^2\ x_2$，可以删除其中一个特征</li>
<li>特征过多(eg.$m\leq n$)<ul>
<li>删除一些特征，或正则化(regularization) </li>
</ul>
</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Andrew-Ng/" rel="tag"># Andrew Ng</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/01/19/MachineLearning_AndrewNg_3/" rel="prev" title="【Andrew Ng】Machine Learning | 3 Linear Algebra review">
      <i class="fa fa-chevron-left"></i> 【Andrew Ng】Machine Learning | 3 Linear Algebra review
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/02/15/Paper_DeepTextClassificationCanBeFooled/" rel="next" title="【论文精读】Deep text classification can be fooled">
      【论文精读】Deep text classification can be fooled <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Multiple-Features-%E5%A4%9A%E7%89%B9%E5%BE%81%E9%87%8F"><span class="nav-number">1.</span> <span class="nav-text">1 Multiple Features 多特征量</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Gradient-descent-for-multiple-variables"><span class="nav-number">2.</span> <span class="nav-text">2 Gradient descent for multiple variables</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%AA%E6%9C%89%E4%B8%80%E4%B8%AA%E7%89%B9%E5%BE%81%E5%80%BC"><span class="nav-number">2.1.</span> <span class="nav-text">只有一个特征值</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8D%E6%AD%A2%E4%B8%80%E4%B8%AA%E7%89%B9%E5%BE%81%E5%80%BC"><span class="nav-number">2.2.</span> <span class="nav-text">不止一个特征值</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Gradient-Descent-in-Practice-I-Feature-Scaling-%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE"><span class="nav-number">3.</span> <span class="nav-text">3 Gradient Descent in Practice I - Feature Scaling 特征缩放</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Gradient-Descent-in-Practice-II-Learning-rate-%E5%AD%A6%E4%B9%A0%E7%8E%87"><span class="nav-number">4.</span> <span class="nav-text">4 Gradient Descent in Practice II - Learning rate 学习率</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E7%A1%AE%E4%BF%9D%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%98%AF%E6%AD%A3%E7%A1%AE%E5%B7%A5%E4%BD%9C%E7%9A%84"><span class="nav-number">4.1.</span> <span class="nav-text">如何确保梯度下降是正确工作的</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Debugging-gradient-descent"><span class="nav-number">4.1.1.</span> <span class="nav-text">Debugging gradient descent</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Automatic-convergence-test"><span class="nav-number">4.1.2.</span> <span class="nav-text">Automatic convergence test</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%AD%A6%E4%B9%A0%E7%8E%87-alpha"><span class="nav-number">4.2.</span> <span class="nav-text">如何选择学习率 $\alpha$</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-Features-and-Polynomial-Regression-%E7%89%B9%E5%BE%81%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92"><span class="nav-number">5.</span> <span class="nav-text">5 Features and Polynomial Regression 特征与多项式回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Housing-prices-prediction"><span class="nav-number">5.1.</span> <span class="nav-text">Housing prices prediction</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-Linear-regression-with-multiple-variables-%E2%80%93-Normal-equation-%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B"><span class="nav-number">6.</span> <span class="nav-text">6 Linear regression with multiple variables – Normal equation 正规方程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Intuition"><span class="nav-number">6.1.</span> <span class="nav-text">Intuition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BE%8B%E5%AD%90"><span class="nav-number">6.2.</span> <span class="nav-text">例子</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#design-matrix-%E8%AE%BE%E8%AE%A1%E7%9F%A9%E9%98%B5"><span class="nav-number">6.3.</span> <span class="nav-text">design matrix 设计矩阵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%92%8C%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-number">6.4.</span> <span class="nav-text">梯度下降和正规方程的优缺点</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-Linear-regression-with-multiple-variables-%E2%80%93-Normal-equation-and-non-invertibility"><span class="nav-number">7.</span> <span class="nav-text">7 Linear regression with multiple variables – Normal equation and non-invertibility</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#X-TX-%E4%B8%8D%E5%8F%AF%E9%80%86%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%8E%9F%E5%9B%A0"><span class="nav-number">7.1.</span> <span class="nav-text">$X^TX$不可逆的两种原因</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="VikingWang"
      src="/images/avatar.JPG">
  <p class="site-author-name" itemprop="name">VikingWang</p>
  <div class="site-description" itemprop="description">这是一个需要耐心等着加载的博客</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">39</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">VikingWang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
